---
title: "Slingshot: Lineage Inference for Single-cell Data"
author: "Kelly Street"
date: "`r Sys.Date()`"
bibliography: bibFile.bib
output: 
  BiocStyle::html_document:
    toc: true
vignette: >
  %\VignetteEncoding{UTF-8}
---

<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{slingshot Vignette}
-->

```{r options, results="hide", include=FALSE, cache=FALSE, results='hide', message=FALSE}
knitr::opts_chunk$set(fig.align="center", cache=TRUE,error=FALSE, #make it stop on error
fig.width=5, fig.height=5, autodep=TRUE, out.width="600px", out.height="600px", results="markup", echo=TRUE, eval=TRUE)
#knitr::opts_knit$set(stop_on_error = 2L) #really make it stop
#knitr::dep_auto()
options(getClass.msg=FALSE)
graphics:::par(pch = 16, las = 1)
set.seed(12345) ## for reproducibility

library(slingshot)
```

# Introduction

This vignette will demonstrate a full single-cell lineage analysis workflow, with particular emphasis on the processes of lineage reconstruction and pseudotime inference. We will make use of the `slingshot` package proposed in [CITE slingshot] and show how it may be applied in a broad range of settings.

The goal of `slingshot` is to use clusters of cells to uncover global structure and convert this structure into smooth lineages represented by one-dimensional variables, called "pseudotime." We provide tools for learning cluster relationships in an unsupervised or semi-supervised manner and constructing smooth curves representing each lineage, along with visualization methods for each step.

## Overview

The minimal input to `slingshot` is a matrix representing the cells in a reduced-dimensional space and a vector of cluster labels. If no cluster labels are provided, `slingshot` will treat the data as a single cluster and fit a standard principal curve. With these two inputs, the analysis then procedes:

* Find connections between clusters with the `getLineages` function, optionally specifying known start and end points.
* Construct smooth curves and pseudotime variables with the `getCurves` function.
* Assess the output of each step with built-in visualization tools.

Each of these steps is described in detail below. For now, we claim that using clusters of cells (rather than individual cells) to define global structure improves the stability of inferred lineages and smooth curves in place of piecewise-linear ones reduces variability in the inferred pseudotime variables.

## Datasets

We will work with two simulated datasets in this vignette. The first is generated by the `splatter` package [CITE splatter], using parameters inferred from the single-cell dataset contained in the `HSMMSingleCell` package. This dataset consists of a full $47192 \text{ genes} \times 200 \text{ cells}$ matrix of expression values and will be used to demonstrate a full ``start-to-finish'' workflow. 

```{r data_splat, message=FALSE, cache=TRUE}
# library(splatter)
# library(HSMMSingleCell)
# data("HSMM_expr_matrix")
# counts <- round(HSMM_expr_matrix)
# params <- splatEstimate(counts)
# params <- setParams(params, update = list(groupCells = 200, path.nonlinearProb = .5, de.prob = .6, de.facLoc = 1, de.facScale = 2, path.length=100))
# sim <- splatSimulate(params, method = "paths")
load('~/splatsim.RData')
dim(sim)
```

The second dataset is provided with the `slingshot` and consists of a $140 \text{ cells} \times 2 \text{ dimensions}$ matrix of coordinates. This dataset will allow us to demonstrate some of the additional functionality offered by `slingshot`.

```{r data_sling}
data("slingshotExample")
dim(rd) # data representing cells in a reduced dimensional space
length(cl) # vector of cluster labels
```

# Upstream Analysis

## Gene Filtering

To begin our analysis of the first simulated dataset, we need to reduce the dimensionality of our data and filtering out noisy genes is a typical first step. This will help improve the speed of downstream analyses, while keeping the loss of information to a minimum.

For the gene filtering step, we will retain any genes that are robustly expressed in at least some percentage of cells, making them potentially interesting cell-type marker genes. For the `splatter` dataset, we define a gene as being "robustly expressed" if it has a read count of 2 or more and we set the minimum percentage of cells robustly expressing a gene to 5%.

```{r genefilt, cache=TRUE}
geneFilt <- apply(exprs(sim),1, function(gene){
  sum(gene >= 2) >= .05 * ncol(sim)
})
mean(geneFilt) # percentage of genes retained
sum(exprs(sim)[geneFilt,]) / sum(exprs(sim)) # percentage of reads retained
sim <- sim[geneFilt,]
```


## Normalization

Another important early step in most RNA-Seq analysis pipelines is the choice of normalization method. This allows us to remove unwanted technical or biological artifacts from the data, such as batch, sequencing depth, cell cycle effects, etc. In practice, it is valuable to compare a variety of normalization techniques and compare them along different evaluation criteria, for which we recommend the `SCONE` package [CITE scone].

Since we are working with simulated data, we have the advantage of knowing what effects are present. In this case, we know that each simulated cell had a unique expected library size and we will apply quantile normalization to remove this effect.

```{r norm1}
FQnorm <- function(counts){
  rk <- apply(counts,2,rank,ties.method='min')
  counts.sort <- apply(counts,2,sort)
  refdist <- apply(counts.sort,1,median)
  norm <- apply(rk,2,function(r){ refdist[r] })
  rownames(norm) <- rownames(counts)
  return(norm)
}
exprs(sim) <- FQnorm(exprs(sim))
```

## Dimensionality Reduction

The fundamental assumption of `slingshot` is that cells which are transcriptionally similar will be close to each other in some reduced-dimensional space. Since we use Euclidean distances in constructing lineages and measuring pseudotime, it is important to have a low-dimensional representation of the data.

There are many methods available for this task and we will intentionally avoid the issue of determining which is the "best" method, as this likely depends on the type of data, method of collection, upstream computational choices, and many other factors. For the sake of time and simplicity, we will use principal components analysis (PCA).

When performing PCA, we do not scale the genes by their variance because we do not believe that all genes are equally informative. We want to find signal in the robustly expressed, highly variable genes, not dampen this signal by forcing equal variance across genes.

```{r pca, cache=TRUE}
pca <- prcomp(t(log1p(exprs(sim))), scale. = FALSE)
splat.rd <- pca$x[,1:2]

plot(splat.rd, col = topo.colors(100)[sim$Step], pch=16, asp = 1)
```

## Clustering Cells

The final input to `slingshot` is a vector of cluster labels for the cells. As we noted above, this is not strictly necessary for datasets in which researchers are confident that only a single lineage is present, but it is highly recommended nonetheless, to allow for the potential discovery of novel branching events.

The clusters identified in this step will be used to determine the global structure of the underlying lineages (that is, their number, when they branch off from one another, and the approximate locations of those branching events). This is different than the typical goal of clustering single-cell data, which is to identify all biologically relevant cell types present in the dataset. For example, when determining global lineage structure, there is no need to distinguish between immature and mature neurons since both cell types will, presumably, fall along the same segment of a lineage.

For the analysis of the simulated data, we implement k-means clustering which similarly assumes that Euclidean distance in a low-dimensional space reflect biological differences between cells. As shown in [CITE slingshot], simultaneous principal curves are quite robust to the choice of k, so we choose a k of 5 somewhat arbitrarily. If k is too low, we may miss a true branching event and if k is too high or there is an abundance of small clusters, we may begin to see spurious branching events.

```{r clustering}
splat.cl <- kmeans(splat.rd, centers = 5)$cluster

plot(splat.rd, col = brewer.pal(9,"Set1")[splat.cl], pch=16, asp = 1)
```

# Using Slingshot

## Assigning clusters to lineages

The `getLineages` function takes as input an `n x p` matrix and a vector of clustering results of length `n`. It then maps connections between adjacent clusters using a minimum spanning tree (MST) and identifies paths through these connections that represent potential lineages.

This analysis can be performed in an entirely unsupervised manner or in a semi-supervised manner by specifying known beginning and end point clusters. We recommend that you specify a root cluster; this will have no effect on how the clusters are connected, but it will allow for nicer curves in datasets with a branching structure. Pre-specified end point clusters will be constrained to only one connection.

```{r lines_unsup}
l1 <- getLineages(rd, cl)
l1
plot(rd, col = brewer.pal(9,"Set1")[cl], asp = 1, pch = 16)
lines(l1, lwd = 3)
```

Running `getLineages` with no supervision produces the connections shown above. Since no root cluster was specified, `slingshot` picked one of the leaf-node clusters to be the beginning, based on a simple parsimony rule. The root cluster is the leaf-node cluster connected by a green line.

```{r lines_sup_start}
l2 <- getLineages(rd, cl, start.clus = '4')
l2
plot(rd, col = brewer.pal(9,"Set1")[cl], asp = 1, pch = 16)
lines(l2, lwd = 3)
```

When we specify a root cluster we get the same connections and the only difference is which line is drawn in green.

```{r lines_sup_end}
l3 <- getLineages(rd, cl, end.clus = '3')
l3
plot(rd, col = brewer.pal(9,"Set1")[cl], asp = 1, pch = 16)
lines(l3, lwd = 3)
```

Here we demonstrate the ability to specify end point clusters, which puts a constraing on the connections. We now draw the MST subject to the constraint that given end point clusters must be leaves. Pre-specified end point clusters are connected by red lines.

There are a few additional arguments we could have passed to `getLineages` for more greater control:

* `dist.fun` is a function for computing distances between clusters. The default is squared distance between cluster centers normalized by their joint covariance matrix.
* `omega` is a granularity parameter, allowing the user to set an upper limit on connection distances. It takes values between 0 and 1 (or `Inf`), representing a percentage of the largest observed distance.
* `distout` is a logical value, indicating whether the user wants the pairwise cluster distance matrix to be returned with the output.

After constructing the MST, `getLineages` identifies paths through the tree to designate as lineages. At this stage, a lineage will consist of an ordered set of cluster names, starting with the root cluster and ending with a leaf. The output of `getLineages` is a list of these vectors, along with some additional information on how they were constructed.

## Constructing smooth curves and ordering cells

In order to model development along these various lineages, we will construct smooth curves with the function `getCurves`. Using smooth curves based on all the cells eliminates the problem of cells projecting onto vertices of piece-wise linear trajectories and makes `slingshot` more robust to noise in the clustering results.

In order to construct smooth lineages, `getCurves` follows an iterative process similar to that of principal curves presented in [@princurve]. When there is only a single lineage, the resulting curve is simply the principal curve through the center of the data, with one adjustment: the initial curve is constructed with the linear connections between cluster centers rather than the first prinicpal component of the data. This adjustment adds stability and typically hastens the algorithm's convergence.

When there are two or more lineages, we add an additional step to the algorithm: averaging curves near shared cells. Both lineages should agree fairly well on cells that have yet to differentiate, so at each iteration we average the curves in the neighborhood of these cells. This increases the stability of the algorithm and produces smooth branching lineages.

```{r curves}
c1 <- getCurves(l1)
c1
plot(rd, col = brewer.pal(9,"Set1")[cl], asp = 1, pch = 16)
lines(c1, lwd = 3)
```

The output of `getCurves` is a list with one element per curve. Each element is an object of the `principal.curve` class, with the following slots:

* `s`: the matrix of points that make up the curve. These correspond to the orthogonal projections of the data points, but oredered such the `lines(s)` will produce a smooth curve.
* `tag`: the indices of the original data points in `s`.
* `lambda`: arclengths of the points in `s` along the curve.
* `dist`: the total squared distance between data points and their projections onto the curve.
* `pseudotime`: the vector of pseudotime values along this lineage.

# Downstream Analysis

## Identifying temporally expressed genes

Typically, the next step will be to find genes that change their expression as a function of developmental time. This can be done using the full genes-by-samples data matrix, but we will use the subset consisting of the 1,000 most variable genes.

```{r genedata}
#data('var_genes')
```

For a quick analysis, we will regress each gene on the two pseudotime vectors we have generated, using a general additive model (GAM). This allows us to detect non-linear patterns in gene expression over developmental time.

```{r fitgam}
# gam.pval <- vector("list",length(crv))
# for(l in 1:length(crv)){
#   t <- crv[[l]]$pseudotime
#   y <- vargenes[, match(rownames(crv[[l]]$s[!is.na(t),]),rownames(rd))]
#   t <- t[! is.na(t)]
#   gam.pval[[l]] <- apply(y,1,function(z){
#     d <- data.frame(z=z, t=t)
#     tmp <- gam(z ~ lo(t), data=d)
#     p <- summary(tmp)[4][[1]][1,5]
#     p
#   })
# }
```

We can then pick out the top genes for each lineage and visualize their expression over developmental time with a heatmap.

```{r heatmaps}
# topgenes1 <- names(sort(gam.pval[[1]], decreasing = FALSE))[1:100]
# heatdata1 <- vargenes[rownames(vargenes) %in% topgenes1, order(crv[[1]]$pseudotime, na.last = NA)]
# heatclus1 <- clus[clus!='-1'][order(crv[[1]]$pseudotime, na.last = NA)]
# ce1 <- clusterExperiment(heatdata1, heatclus1, transformation=identity)
# plotHeatmap(ce1, clusterSamplesData="orderSamplesValue")
# 
# topgenes2 <- names(sort(gam.pval[[2]], decreasing = FALSE))[1:100]
# heatdata2 <- vargenes[rownames(vargenes) %in% topgenes2, order(crv[[2]]$pseudotime, na.last = NA)]
# heatclus2 <- clus[clus!='-1'][order(crv[[2]]$pseudotime, na.last = NA)]
# ce2 <- clusterExperiment(heatdata2, heatclus2, transformation=identity)
# plotHeatmap(ce2, clusterSamplesData="orderSamplesValue")
```

# Session Info

```{r session}
sessionInfo()
```

# References

